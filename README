# How to run?

1. Download the databases.

  - https://nats.gitlab.io/swc/
  - https://commonvoice.mozilla.org/de/datasets
  - https://www.caito.de/2019/01/03/the-m-ailabs-speech-dataset/
  
2. Run the preprocessing scripts

  - ./preprocessing/mai/convert.py --root_dir <where you extracted the database> --save_dir <where you want to store the database>
  - ./preprocessing/mcv/convert.py --root_dir <where you extracted the database> --save_dir <where you want to store the database>
  - ./preprocessing/swc/convert.py --root_dir <where you extracted the database> --save_dir <where you want to store the database>
  
3. Run the tokenizer

  - Set your paths correctly and run:
  - ./tokenizer/run.sh
  
4. Run ./seq2seq/train.py hparams/<setup>.yml
