# How to run?

1. Download the databases.

  - https://nats.gitlab.io/swc/
  - https://commonvoice.mozilla.org/de/datasets
  - https://www.caito.de/2019/01/03/the-m-ailabs-speech-dataset/

2. Extract them in different folders in the same root folder

//<root folder>/source/mcv
//<root folder>/source/swc
//<root folder>/source/mai
  
2. Run the preprocessing scripts

  - ./preprocessing/mai/convert.py --root_dir <root folder>/source/mai --save_dir <root folder>/processed/mai
  - ./preprocessing/mcv/convert.py --root_dir <root folder>/source/mcv --save_dir <root folder>/processed/mcv
  - ./preprocessing/swc/convert.py --root_dir <root folder>/source/swc --save_dir <root folder>/processed/swc
  
3. Run the tokenizer

  - Set your paths correctly and run:
  - ./tokenizer/run.sh
  
4. Run ./seq2seq/train.py hparams/<setup>.yml
